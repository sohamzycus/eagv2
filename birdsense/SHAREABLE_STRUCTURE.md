# ğŸ“ BirdSense Project Structure

**Share this document with your ML architect for a complete project overview.**

---

## Repository Structure

```
birdsense/
â”œâ”€â”€ ğŸ“„ README.md                     # Project overview & quick start
â”œâ”€â”€ ğŸ“„ ARCHITECTURE.md               # Technical architecture (with SAM-Audio)
â”œâ”€â”€ ğŸ“„ DEPLOY.md                     # Deployment guide (HuggingFace, Render, etc.)
â”œâ”€â”€ ğŸ“„ RESEARCHER_GUIDE.md           # Guide for field researchers
â”œâ”€â”€ ğŸ“„ QUICK_START.md                # 5-minute setup guide
â”‚
â”œâ”€â”€ ğŸ“„ docs/
â”‚   â””â”€â”€ ML_ARCHITECT_REVIEW.md       # Detailed enterprise architecture review
â”‚
â”œâ”€â”€ âš™ï¸ config/
â”‚   â””â”€â”€ config.yaml                  # Model & API configuration
â”‚
â”œâ”€â”€ ğŸµ audio/                        # Audio Processing Module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessor.py              # Audio loading, filtering, mel-spectrogram
â”‚   â”œâ”€â”€ augmentation.py              # Data augmentation (noise, stretch, pitch)
â”‚   â”œâ”€â”€ encoder.py                   # CNN audio encoder (EfficientNet-style)
â”‚   â””â”€â”€ sam_audio.py                 # Meta SAM-Audio integration
â”‚
â”œâ”€â”€ ğŸ§  models/                       # ML Models
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audio_classifier.py          # Species classifier head
â”‚   â””â”€â”€ novelty_detector.py          # Out-of-distribution detection
â”‚
â”œâ”€â”€ ğŸ—ƒï¸ data/                         # Data Management
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ species_db.py                # India bird species database (25+)
â”‚
â”œâ”€â”€ ğŸ¤– llm/                          # LLM Integration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ollama_client.py             # Ollama API client
â”‚   â””â”€â”€ reasoning.py                 # LLM-based species reasoning
â”‚
â”œâ”€â”€ ğŸ“¡ api/                          # REST API
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ server.py                    # FastAPI server with streaming
â”‚
â”œâ”€â”€ ğŸŒ webapp/                       # Web User Interface
â”‚   â”œâ”€â”€ index.html                   # Main page
â”‚   â”œâ”€â”€ styles.css                   # Dark theme styling
â”‚   â””â”€â”€ app.js                       # Recording, upload, visualization
â”‚
â”œâ”€â”€ ğŸ“Š training/                     # Model Training
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ xeno_canto.py                # Xeno-Canto data downloader
â”‚   â”œâ”€â”€ dataset.py                   # PyTorch dataset
â”‚   â””â”€â”€ trainer.py                   # Training loop with calibration
â”‚
â”œâ”€â”€ ğŸ§ª tests/                        # Test Suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_audio_conditions.py     # 48 comprehensive tests
â”‚
â”œâ”€â”€ ğŸ“ samples/                      # Test audio samples
â”‚   â”œâ”€â”€ koel_sample.wav
â”‚   â”œâ”€â”€ cuckoo_sample.wav
â”‚   â”œâ”€â”€ kingfisher_sample.wav
â”‚   â””â”€â”€ mixed_birds.wav
â”‚
â”œâ”€â”€ ğŸ“ checkpoints/                  # Model weights (gitignored)
â”‚
â”œâ”€â”€ ğŸ³ Dockerfile                    # Container build
â”œâ”€â”€ ğŸ³ docker-compose.yml            # Multi-container deployment
â”œâ”€â”€ ğŸ¨ huggingface_app.py            # Gradio app for HuggingFace Spaces
â”œâ”€â”€ ğŸ“¦ requirements.txt              # Python dependencies
â”œâ”€â”€ ğŸ“¦ requirements_hf.txt           # Minimal deps for HuggingFace
â”œâ”€â”€ âš™ï¸ setup.py                      # Package setup
â”œâ”€â”€ ğŸš€ run_demo.py                   # CLI demo runner
â””â”€â”€ ğŸš« .gitignore                    # Git ignore rules
```

---

## Key Components

### 1ï¸âƒ£ Audio Processing Pipeline

| File | Purpose | Key Functions |
|------|---------|---------------|
| `audio/preprocessor.py` | Load, filter, normalize audio | `process()`, `get_audio_quality_assessment()` |
| `audio/augmentation.py` | Data augmentation | `add_noise()`, `time_stretch()`, `pitch_shift()` |
| `audio/encoder.py` | CNN feature extraction | `forward()` â†’ 384-dim embedding |
| `audio/sam_audio.py` | Meta SAM-Audio separation | `enhance_audio()`, `separate_sources()` |

### 2ï¸âƒ£ ML Models

| File | Purpose | Architecture |
|------|---------|--------------|
| `models/audio_classifier.py` | Species classification | Linear head on 384-dim embedding |
| `models/novelty_detector.py` | Detect unknown species | Mahalanobis distance |

### 3ï¸âƒ£ LLM Integration

| File | Purpose | Model |
|------|---------|-------|
| `llm/ollama_client.py` | Local LLM inference | qwen2.5:3b (recommended) |
| `llm/reasoning.py` | Context-aware reasoning | Habitat/season validation |

### 4ï¸âƒ£ API & Web Interface

| File | Purpose | Endpoints |
|------|---------|-----------|
| `api/server.py` | FastAPI backend | `/identify`, `/species`, `/health` |
| `webapp/*` | Researcher UI | Recording, upload, histogram |
| `huggingface_app.py` | Gradio interface | For public deployment |

---

## Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     BIRDSENSE DATA FLOW                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   FIELD RECORDING                                                â”‚
â”‚        â”‚                                                         â”‚
â”‚        â–¼                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚   â”‚  Web App    â”‚    â”‚  REST API   â”‚    â”‚   Mobile    â”‚        â”‚
â”‚   â”‚  /app       â”‚â”€â”€â”€â–¶â”‚  /identify  â”‚â—€â”€â”€â”€â”‚   SDK       â”‚        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                             â”‚                                    â”‚
â”‚                             â–¼                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚                    PROCESSING PIPELINE                    â”‚ â”‚
â”‚   â”‚                                                           â”‚ â”‚
â”‚   â”‚  1. SAM-Audio â†’ Source separation (if noisy)             â”‚ â”‚
â”‚   â”‚  2. Preprocessor â†’ Mel-spectrogram                       â”‚ â”‚
â”‚   â”‚  3. Encoder â†’ 384-dim embedding                          â”‚ â”‚
â”‚   â”‚  4. Classifier â†’ Top-5 predictions                       â”‚ â”‚
â”‚   â”‚  5. Novelty Detector â†’ Out-of-range check                â”‚ â”‚
â”‚   â”‚  6. LLM Reasoning â†’ Final species + explanation          â”‚ â”‚
â”‚   â”‚                                                           â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                             â”‚                                    â”‚
â”‚                             â–¼                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚                      RESPONSE                             â”‚ â”‚
â”‚   â”‚                                                           â”‚ â”‚
â”‚   â”‚  {                                                        â”‚ â”‚
â”‚   â”‚    "species": "Asian Koel",                              â”‚ â”‚
â”‚   â”‚    "confidence": 0.87,                                   â”‚ â”‚
â”‚   â”‚    "reasoning": "The distinctive 'ku-oo' call...",       â”‚ â”‚
â”‚   â”‚    "novelty_alert": null                                 â”‚ â”‚
â”‚   â”‚  }                                                        â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Technology Stack

| Layer | Technology | Rationale |
|-------|------------|-----------|
| **Audio Processing** | librosa, scipy, soundfile | Industry-standard bioacoustics |
| **ML Framework** | PyTorch | Flexibility, research-friendly |
| **Audio Separation** | Meta SAM-Audio | State-of-the-art, zero-shot |
| **LLM** | Ollama (qwen2.5:3b) | Local, private, fast |
| **API** | FastAPI | Modern, async, auto-docs |
| **Web UI** | Vanilla JS + CSS | Lightweight, no build step |
| **Deployment** | Docker, HuggingFace | Free, easy sharing |

---

## Model Architecture Summary

```
Input: Audio (WAV/MP3, any sample rate)
         â”‚
         â–¼
SAM-Audio (Optional)
  â”œâ”€â”€ Source separation
  â”œâ”€â”€ Noise removal
  â””â”€â”€ Multi-bird handling
         â”‚
         â–¼
Preprocessor
  â”œâ”€â”€ Resample to 32kHz
  â”œâ”€â”€ Bandpass filter (50Hz-14kHz)
  â””â”€â”€ Mel-spectrogram (128 bins)
         â”‚
         â–¼
CNN Encoder (EfficientNet-style)
  â”œâ”€â”€ 7 MBConv stages
  â”œâ”€â”€ SE attention blocks
  â”œâ”€â”€ ~2M parameters
  â””â”€â”€ Output: 384-dim embedding
         â”‚
         â–¼
Classifier Head
  â”œâ”€â”€ Linear (384 â†’ num_classes)
  â”œâ”€â”€ Softmax
  â””â”€â”€ Output: Top-K predictions
         â”‚
         â–¼
LLM Reasoning (Ollama)
  â”œâ”€â”€ Context integration
  â”œâ”€â”€ Habitat/season validation
  â””â”€â”€ Output: Final species + reasoning
```

---

## API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/identify` | Identify species from audio |
| `POST` | `/api/v1/identify/stream` | Streaming SSE response |
| `GET` | `/api/v1/species` | List all species |
| `GET` | `/api/v1/species/{id}` | Species details |
| `GET` | `/api/v1/health` | Health check |
| `GET` | `/api/v1/status` | Model & system status |
| `GET` | `/app` | Web UI |
| `GET` | `/docs` | API documentation |

---

## Running Locally

```bash
# 1. Setup
cd birdsense
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. Install Ollama (for LLM reasoning)
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull qwen2.5:3b

# 3. Start API server
uvicorn api.server:app --host 0.0.0.0 --port 8000

# 4. Open in browser
open http://localhost:8000/app
```

---

## Deployment Options

| Platform | Cost | URL Pattern | GPU |
|----------|------|-------------|-----|
| **HuggingFace Spaces** | FREE | `huggingface.co/spaces/USER/birdsense` | Optional |
| Render | FREE | `birdsense.onrender.com` | No |
| Railway | $5/mo | `birdsense.up.railway.app` | No |
| Fly.io | FREE | `birdsense.fly.dev` | No |
| Docker | Self-host | Custom | Optional |

---

## Files for ML Architect Review

1. **`docs/ML_ARCHITECT_REVIEW.md`** - Comprehensive enterprise review document
2. **`ARCHITECTURE.md`** - Visual architecture diagrams with SAM-Audio integration
3. **`README.md`** - Project overview and results
4. **`training/trainer.py`** - Training pipeline with calibration
5. **`audio/sam_audio.py`** - Meta SAM-Audio integration

---

## Contact

**Project:** BirdSense - CSCR Initiative  
**Status:** MVP Ready for Training & Deployment  
**Next:** Train on Xeno-Canto data, deploy to HuggingFace Spaces

