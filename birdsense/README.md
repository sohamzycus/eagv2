# ğŸ¦ BirdSense - AI Bird Identification

**Developed by Soham**

A novel hybrid AI system for bird identification combining multiple approaches for superior accuracy.

## ğŸ§  Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        BirdSense Hybrid Architecture                     â”‚
â”‚                           Developed by Soham                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚   AUDIO     â”‚     â”‚   IMAGE     â”‚     â”‚ DESCRIPTION â”‚                â”‚
â”‚  â”‚   Input     â”‚     â”‚   Input     â”‚     â”‚   Input     â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚         â”‚                   â”‚                   â”‚                        â”‚
â”‚         â–¼                   â”‚                   â”‚                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚                   â”‚                        â”‚
â”‚  â”‚  META SAM-Audio â”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚  â€¢ Noise filter â”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚  â€¢ Call isolate â”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚  â€¢ Segment det. â”‚        â”‚                   â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚                   â”‚                        â”‚
â”‚           â”‚                 â”‚                   â”‚                        â”‚
â”‚           â–¼                 â”‚                   â”‚                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚                   â”‚                        â”‚
â”‚  â”‚    BirdNET      â”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚   (Cornell)     â”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚  â€¢ 6000+ speciesâ”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚  â€¢ Spectrogram  â”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚  â€¢ CNN pattern  â”‚        â”‚                   â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚                   â”‚                        â”‚
â”‚           â”‚                 â”‚                   â”‚                        â”‚
â”‚           â–¼                 â–¼                   â–¼                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚                    LLM Reasoning Layer                       â”‚        â”‚
â”‚  â”‚                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”‚        â”‚
â”‚  â”‚   phi4 (14B)              LLaVA (7B)           phi4 (14B)    â”‚        â”‚
â”‚  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚        â”‚
â”‚  â”‚   â€¢ Context valid.        â€¢ Vision analysis    â€¢ Text reason â”‚        â”‚
â”‚  â”‚   â€¢ Location filter       â€¢ Feature extract    â€¢ Description â”‚        â”‚
â”‚  â”‚   â€¢ Season reason.        â€¢ Multi-bird det.    â€¢ matching    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                               â”‚                                          â”‚
â”‚                               â–¼                                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                    â”‚   Deduplication &   â”‚                               â”‚
â”‚                    â”‚   Confidence Merge  â”‚                               â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                               â”‚                                          â”‚
â”‚                               â–¼                                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                    â”‚  STREAMING RESULTS  â”‚                               â”‚
â”‚                    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚                               â”‚
â”‚                    â”‚  â€¢ Real-time trail  â”‚                               â”‚
â”‚                    â”‚  â€¢ Unique species   â”‚                               â”‚
â”‚                    â”‚  â€¢ Wikipedia images â”‚                               â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Key Features

### 1. **Hybrid BirdNET + LLM Pipeline**
- BirdNET (Cornell Lab): Pattern-based spectrogram analysis for 6000+ species
- LLM Validation: Contextual reasoning using location, season, and behavior
- **Novel contribution**: Combines best of both approaches

### 2. **META SAM-Audio Processing**
- Inspired by Meta's Segment Anything Model
- Isolates bird calls from background noise
- Detects multiple birds in same recording
- Frequency band separation for multi-species detection

### 3. **Feature-Based Identification**
- Systematic feature analysis (beak, head, body patterns)
- No hardcoded species rules
- Flexible for any bird species

### 4. **Streaming Results**
- Real-time analysis trail shows progress
- Birds displayed as identified (not waiting for all)
- Deduplication ensures each species shown once

## ğŸš€ Quick Start

### Option 1: Cloud Hosting (FREE, Permanent, Auto-Deploy)

Deploy to **Render.com** with **Groq API** (100% FREE, no credit card):

```bash
./deploy.sh cloud   # Shows step-by-step instructions
```

**5-Minute Setup:**
1. Get **FREE** API key at https://console.groq.com (no credit card!)
2. Go to https://render.com â†’ New â†’ Web Service
3. Connect GitHub repo: `sohamzycus/eagv2`, Root: `birdsense`, Runtime: Docker
4. Add env var: `GROQ_API_KEY` (your free Groq key)
5. Deploy! **Auto-refreshes on every git push.**

### Option 2: Local with GPU (Best Accuracy)

```bash
./deploy.sh local   # Sets up Ollama + models + runs app
```

### Option 3: Docker (Portable)

```bash
./deploy.sh docker  # Runs in Docker containers
```

### Option 4: Manual Setup

```bash
# 1. Prerequisites
brew install python@3.12 ollama  # Mac
# Or: curl -fsSL https://ollama.ai/install.sh | sh  # Linux

# 2. Start Ollama and pull models
ollama serve &
ollama pull llava:7b
ollama pull phi4

# 3. Setup Python environment
cd birdsense
python3.12 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 4. Run
python app.py
# Open http://localhost:7860
```

### System Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| RAM | 8 GB | 16 GB |
| Storage | 15 GB | 25 GB |
| GPU | None (CPU works) | Apple M1+ or NVIDIA |
| Python | 3.12 | 3.12 |

## ğŸ“ Project Structure

```
birdsense/
â”œâ”€â”€ app.py              # Single codebase (auto-detects Ollama or Groq)
â”œâ”€â”€ prompts.py          # External LLM prompts
â”œâ”€â”€ confusion_rules.py  # Feature-based validation
â”œâ”€â”€ feedback.py         # Feedback & analytics collection
â”œâ”€â”€ export_data.py      # Export collected data
â”œâ”€â”€ deploy.sh           # One-command deployment (local/docker/cloud)
â”œâ”€â”€ Dockerfile          # Docker container config
â”œâ”€â”€ docker-compose.yml  # Multi-container setup
â”œâ”€â”€ render.yaml         # Render.com auto-deploy config
â”œâ”€â”€ requirements.txt    # Local dependencies (with BirdNET)
â”œâ”€â”€ requirements_cloud.txt  # Docker dependencies (lightweight)
â”œâ”€â”€ .github/workflows/  # Auto-deploy on GitHub push
â””â”€â”€ README.md           # This file
```

### Single Codebase - Auto-Detects Runtime:

| Mode | Detection | Models | Best For |
|------|-----------|--------|----------|
| **Local** | Ollama running | LLaVA + phi4 + BirdNET | Best accuracy |
| **Cloud** | GROQ_API_KEY set | Llama 3.2 Vision | FREE hosting |

## ğŸ”§ Technology Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| Audio ID | BirdNET (Cornell) + TensorFlow | Spectrogram pattern matching |
| Image ID | LLaVA 7B | Vision-language analysis |
| Text ID | phi4 (14B) | Reasoning & validation |
| Audio Processing | META SAM-Audio | Noise filtering, call isolation |
| UI | Gradio | Web interface |
| Image Source | Wikipedia/iNaturalist | Reference photos |

## ğŸ§ª What Makes BirdSense Novel

1. **Hybrid Ensemble**: First to combine BirdNET + LLM for bird ID
2. **Contextual Validation**: LLM validates ML predictions using location/season
3. **Multi-Modal Fusion**: Audio + Image + Description analysis
4. **Streaming UX**: Real-time progress and results
5. **100% Local**: No cloud APIs required

## ğŸ“Š Comparison

| Feature | BirdNET Only | GPT-5 | BirdSense |
|---------|-------------|-------|-----------|
| Spectrogram Analysis | âœ… | âŒ | âœ… |
| Contextual Reasoning | âŒ | âœ… | âœ… |
| Location Awareness | Basic | âœ… | âœ… |
| Multi-modal | Audio only | Text/Image | **All 3** |
| Runs Locally | âœ… | âŒ | âœ… |
| Species Count | 6000+ | General | **6000+** |

## ğŸŒ Hosting for Testing

Share BirdSense with others for testing and feedback collection:

### Quick Share (Gradio Public URL)

```bash
# Creates a temporary public URL (valid for 72 hours)
python host.py

# Output: "Running on public URL: https://xxx.gradio.live"
```

This uses Gradio's built-in sharing feature - no extra setup required!

### Persistent Hosting Options

| Method | Cost | Setup Complexity | GPU |
|--------|------|------------------|-----|
| **Gradio Share** | Free | â­ (1 command) | Your local GPU |
| **ngrok** | Free tier | â­â­ | Your local GPU |
| **Railway.app** | ~$5/mo | â­â­â­ | CPU only (slow) |
| **VPS + Ollama** | ~$20/mo | â­â­â­â­ | Depends on VPS |

### Share Link Workflow

```bash
# 1. Start public hosting
python host.py

# 2. Share the gradio.live URL with testers
# 3. Testers use the Feedback tab to report results
# 4. Export feedback when done:
python export_data.py --export all
```

## ğŸ“Š Feedback & Sample Collection

BirdSense includes built-in audit and feedback collection:

### In-App Feedback
- **Feedback Tab**: Users can report if identification was correct/incorrect
- **Correct Species**: When wrong, users can provide the correct species
- **Notes**: Additional feedback for edge cases

### Data Export

```bash
# Show summary of collected data
python export_data.py

# Export feedback as JSON
python export_data.py --export feedback

# Export samples (audio/images with corrections)
python export_data.py --export samples

# Export everything
python export_data.py --export all
```

### Analytics Dashboard
Access the **ğŸ“Š Analytics** tab in the app to see:
- Total predictions
- Accuracy from user feedback
- Top identified species
- Breakdown by input type

## ğŸ“ Project Structure

```
birdsense/
â”œâ”€â”€ app.py              # Main application (Gradio UI + pipelines)
â”œâ”€â”€ prompts.py          # External LLM prompts (no hardcoding)
â”œâ”€â”€ confusion_rules.py  # Feature-based validation
â”œâ”€â”€ feedback.py         # Feedback & sample collection
â”œâ”€â”€ host.py             # Public hosting script
â”œâ”€â”€ export_data.py      # Data export utility
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md           # This file
```

## ğŸ”® Future Roadmap

- [ ] Geolocation auto-filtering (lat/lon based species filtering)
- [ ] Spectrogram visualization
- [ ] Custom model fine-tuning on regional data
- [ ] Mobile app (TensorFlow Lite)
- [ ] Offline mode with embedded models

---

**Developed by Soham** | BirdSense v1.0
