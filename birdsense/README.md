# ğŸ¦ BirdSense - AI Bird Identification System

**Developed by Soham**

A novel hybrid AI system for intelligent bird identification using audio, images, and descriptions. BirdSense combines cutting-edge deep learning with traditional ornithological knowledge to deliver accurate species identification.

---

## ğŸŒŸ Key Features

| Feature | Description |
|---------|-------------|
| **ğŸµ Audio Identification** | META SAM-Audio + BirdNET hybrid with multi-bird detection |
| **ğŸ“· Image Identification** | Vision AI with feature-based analysis |
| **ğŸ“ Description Matching** | Natural language bird identification |
| **ğŸ‡®ğŸ‡³ India-Specific Info** | Local names, habitats, birding spots |
| **ğŸ”„ Multi-Backend Support** | Ollama (local) or Azure OpenAI (cloud) |
| **ğŸ“Š Streaming Results** | Real-time analysis trail with accordion view |

---

## ğŸ—ï¸ Novel Hybrid Architecture

BirdSense introduces a **novel multi-stage hybrid architecture** that combines specialized ML models with large language models for superior accuracy.

### Audio Identification Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BIRDSENSE AUDIO PIPELINE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  AUDIO INPUT                                                        â”‚
â”‚       â”‚                                                             â”‚
â”‚       â–¼                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚  STAGE 1: META SAM-Audio            â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Noise filtering                â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Bird call segmentation         â”‚                           â”‚
â”‚  â”‚  â””â”€â”€ Frequency band separation:     â”‚                           â”‚
â”‚  â”‚      â€¢ Very Low (100-500 Hz) - Owls â”‚                           â”‚
â”‚  â”‚      â€¢ Low (500-1500 Hz) - Crows    â”‚                           â”‚
â”‚  â”‚      â€¢ Medium (1500-3000 Hz) - Mynasâ”‚                           â”‚
â”‚  â”‚      â€¢ High (3000-6000 Hz) - Finchesâ”‚                           â”‚
â”‚  â”‚      â€¢ Very High (6000+ Hz)         â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚       â”‚                                                             â”‚
â”‚       â–¼                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚  STAGE 2: BirdNET (Cornell Lab)     â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Spectrogram analysis           â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ 6000+ species recognition      â”‚                           â”‚
â”‚  â”‚  â””â”€â”€ Multi-pass analysis:           â”‚                           â”‚
â”‚  â”‚      â€¢ Full audio analysis          â”‚                           â”‚
â”‚  â”‚      â€¢ Per-frequency-band analysis  â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚       â”‚                                                             â”‚
â”‚       â–¼                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚  STAGE 3: Feature Extraction        â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Frequency range analysis       â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Pattern detection              â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Syllable counting              â”‚                           â”‚
â”‚  â”‚  â””â”€â”€ Rhythm classification          â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚       â”‚                                                             â”‚
â”‚       â–¼                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚  STAGE 4: LLM Validation Layer      â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Contextual reasoning           â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Location/season validation     â”‚                           â”‚
â”‚  â”‚  â””â”€â”€ Confidence adjustment          â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚       â”‚                                                             â”‚
â”‚       â–¼                                                             â”‚
â”‚  IDENTIFIED BIRDS (with enriched info)                             â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Image Identification Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BIRDSENSE IMAGE PIPELINE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  IMAGE INPUT                                                        â”‚
â”‚       â”‚                                                             â”‚
â”‚       â–¼                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚  Vision Model (LLaVA/GPT-4o)        â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Systematic feature analysis:   â”‚                           â”‚
â”‚  â”‚  â”‚   â€¢ BEAK: Color, shape           â”‚                           â”‚
â”‚  â”‚  â”‚   â€¢ HEAD: Crown, eye pattern     â”‚                           â”‚
â”‚  â”‚  â”‚   â€¢ BODY: Plumage, breast        â”‚                           â”‚
â”‚  â”‚  â”‚   â€¢ SIZE: Relative sizing        â”‚                           â”‚
â”‚  â”‚  â””â”€â”€ Multi-bird detection           â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚       â”‚                                                             â”‚
â”‚       â–¼                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚  Enrichment Layer                   â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Wikipedia image fetch          â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Species information            â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Habitat & diet data            â”‚                           â”‚
â”‚  â”‚  â””â”€â”€ India-specific info            â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚       â”‚                                                             â”‚
â”‚       â–¼                                                             â”‚
â”‚  IDENTIFIED BIRDS (with images & facts)                            â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
birdsense/
â”œâ”€â”€ app.py              # Gradio UI (clean, minimal)
â”œâ”€â”€ providers.py        # LLM Provider Factory Pattern
â”‚                       # â”œâ”€â”€ OllamaProvider (local)
â”‚                       # â”œâ”€â”€ OpenAIProvider (public API)
â”‚                       # â””â”€â”€ AzureOpenAIProvider (enterprise)
â”œâ”€â”€ analysis.py         # Bird Identification Logic
â”‚                       # â”œâ”€â”€ SAMAudio (source separation)
â”‚                       # â”œâ”€â”€ BirdNET integration
â”‚                       # â”œâ”€â”€ Feature extraction
â”‚                       # â””â”€â”€ Result formatting
â”œâ”€â”€ prompts.py          # Model-specific prompts
â”œâ”€â”€ confusion_rules.py  # Feature validation hints
â”œâ”€â”€ feedback.py         # User feedback collection
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ Dockerfile          # Cloud deployment
â””â”€â”€ .env               # Local configuration (gitignored)
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.12
- Ollama (for local models)
- Docker (for cloud deployment)

### Local Development

#### 1. Clone and Setup

```bash
cd birdsense

# Create virtual environment
python3.12 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

#### 2. Install Ollama Models (Local Backend)

```bash
# Install Ollama from https://ollama.ai
ollama pull llava:7b      # Vision model
ollama pull phi4:latest   # Text model
```

#### 3. Configure Environment

```bash
# Copy template
cp env-template.txt .env

# Edit .env with your settings:
# Option A: Use Ollama (local) - no API key needed
# Option B: Use Azure OpenAI - add your credentials
```

**Example `.env` for Azure OpenAI:**
```env
IS_AZURE=true
LITELLM_API_KEY=your-azure-api-key
LITELLM_API_BASE=https://your-resource.azure-api.net/your-endpoint
AZURE_DEPLOYMENT=your-deployment-name
AZURE_API_VERSION=2024-02-15-preview
LITELLM_VISION_MODEL=gpt-4o
LITELLM_TEXT_MODEL=gpt-4o
```

#### 4. Run Locally

```bash
python app.py
```

Open **http://localhost:7860** in your browser.

---

## â˜ï¸ Cloud Deployment

### Deploy to Google Cloud Run

#### 1. Build Docker Image

```bash
# Build for linux/amd64 (Cloud Run requirement)
docker buildx build --platform linux/amd64 -t your-dockerhub/birdsense:latest --push .
```

#### 2. Deploy to Cloud Run

```bash
gcloud run deploy birdsense \
  --image docker.io/your-dockerhub/birdsense:latest \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --memory 2Gi \
  --cpu 2 \
  --timeout 300 \
  --set-env-vars "IS_AZURE=true" \
  --set-env-vars "LITELLM_API_KEY=your-api-key" \
  --set-env-vars "LITELLM_API_BASE=https://your-endpoint" \
  --set-env-vars "AZURE_DEPLOYMENT=your-deployment" \
  --set-env-vars "AZURE_API_VERSION=2024-02-15-preview" \
  --set-env-vars "LITELLM_VISION_MODEL=gpt-4o" \
  --set-env-vars "LITELLM_TEXT_MODEL=gpt-4o" \
  --port 7860
```

#### 3. Verify Deployment

```bash
# Get service URL
gcloud run services describe birdsense --region us-central1 --format 'value(status.url)'

# Test
curl https://your-service-url.run.app
```

### Deploy with Docker Compose (Self-hosted)

```yaml
# docker-compose.yml
version: '3.8'
services:
  birdsense:
    image: your-dockerhub/birdsense:latest
    ports:
      - "7860:7860"
    environment:
      - IS_AZURE=true
      - LITELLM_API_KEY=${LITELLM_API_KEY}
      - LITELLM_API_BASE=${LITELLM_API_BASE}
      - AZURE_DEPLOYMENT=${AZURE_DEPLOYMENT}
    restart: unless-stopped
```

```bash
docker-compose up -d
```

---

## ğŸ”§ Backend Configuration

### Option 1: Ollama (Local - Free)

Best for development and privacy-conscious deployments.

| Model | Purpose | Size |
|-------|---------|------|
| LLaVA 7B | Vision | ~4GB |
| phi4 14B | Text/Reasoning | ~8GB |

**Quality**: â­â­â­â­ (Good)

### Option 2: Azure OpenAI (Enterprise)

Best for production with enterprise security.

| Model | Purpose |
|-------|---------|
| GPT-4o | Vision + Text |

**Quality**: â­â­â­â­â­ (Excellent)

### Option 3: OpenAI Public API

Best for quick cloud deployment.

```env
IS_AZURE=false
LITELLM_API_KEY=sk-your-openai-key
LITELLM_API_BASE=https://api.openai.com
LITELLM_VISION_MODEL=gpt-4o
LITELLM_TEXT_MODEL=gpt-4o
```

---

## ğŸ¯ API Endpoints

BirdSense uses Gradio's built-in API. Access programmatically:

```python
from gradio_client import Client

client = Client("https://your-birdsense-url")

# Image identification
result = client.predict(
    image="path/to/bird.jpg",
    location="Mumbai, India",
    api_name="/identify_image"
)

# Audio identification  
result = client.predict(
    audio="path/to/bird_call.wav",
    location="Kerala, India",
    month="March",
    api_name="/identify_audio"
)
```

---

## ğŸ“Š Technical Stack

| Component | Technology |
|-----------|------------|
| **UI Framework** | Gradio 4.x |
| **Audio Analysis** | BirdNET (TensorFlow), scipy, librosa |
| **Vision Models** | LLaVA 7B, GPT-4o |
| **Text Models** | phi4 14B, GPT-4o |
| **Image Sources** | Wikipedia, Wikimedia Commons, iNaturalist |
| **Containerization** | Docker |
| **Cloud Platform** | Google Cloud Run |

---

## ğŸ§ª Testing

### Test Audio Multi-Bird Detection

```python
# Verify SAM-Audio + BirdNET pipeline
from analysis import identify_audio_streaming
import numpy as np

# Generate test audio or load from file
# The pipeline will:
# 1. Separate frequency bands
# 2. Run BirdNET on each band
# 3. Deduplicate and merge results
```

### Test Image Identification

```python
from analysis import fetch_bird_image

# Verify image fetching uses scientific name
url = fetch_bird_image("Great Tit", "Parus major")
print(f"Image URL: {url}")  # Should return Wikipedia image
```

---

## ğŸ”„ Recent Updates

### v5.0 (Latest)
- âœ… **Multi-bird audio detection** via SAM-Audio frequency separation
- âœ… **Fixed bird image fetching** using scientific names
- âœ… **India-specific information** always included
- âœ… **Accordion UI** for multiple results
- âœ… **Refactored architecture** with Factory Pattern
- âœ… **Azure OpenAI support** for enterprise deployment

### Architecture Improvements
- `providers.py` - Clean LLM backend abstraction
- `analysis.py` - Separated identification logic
- `prompts.py` - Externalized all LLM prompts

---

## ğŸ™ Acknowledgments

- **Cornell Lab of Ornithology** - BirdNET model
- **Meta AI** - LLaVA vision-language model
- **OpenAI / Microsoft** - GPT-4o models
- **Ollama** - Local model serving
- **Wikipedia / iNaturalist** - Bird images and data

---

**ğŸ¦ BirdSense** - *Bringing AI to Bird Identification*

*Developed by Soham*
