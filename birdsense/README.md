# ğŸ¦ BirdSense - AI Bird Identification

**Developed by Soham**

A novel hybrid AI system for bird identification combining multiple approaches for superior accuracy.

## ğŸ§  Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        BirdSense Hybrid Architecture                     â”‚
â”‚                           Developed by Soham                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚   AUDIO     â”‚     â”‚   IMAGE     â”‚     â”‚ DESCRIPTION â”‚                â”‚
â”‚  â”‚   Input     â”‚     â”‚   Input     â”‚     â”‚   Input     â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚         â”‚                   â”‚                   â”‚                        â”‚
â”‚         â–¼                   â”‚                   â”‚                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚                   â”‚                        â”‚
â”‚  â”‚  META SAM-Audio â”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚  â€¢ Noise filter â”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚  â€¢ Call isolate â”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚  â€¢ Segment det. â”‚        â”‚                   â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚                   â”‚                        â”‚
â”‚           â”‚                 â”‚                   â”‚                        â”‚
â”‚           â–¼                 â”‚                   â”‚                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚                   â”‚                        â”‚
â”‚  â”‚    BirdNET      â”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚   (Cornell)     â”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚  â€¢ 6000+ speciesâ”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚  â€¢ Spectrogram  â”‚        â”‚                   â”‚                        â”‚
â”‚  â”‚  â€¢ CNN pattern  â”‚        â”‚                   â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚                   â”‚                        â”‚
â”‚           â”‚                 â”‚                   â”‚                        â”‚
â”‚           â–¼                 â–¼                   â–¼                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚                    LLM Reasoning Layer                       â”‚        â”‚
â”‚  â”‚                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”‚        â”‚
â”‚  â”‚   phi4 (14B)              LLaVA (7B)           phi4 (14B)    â”‚        â”‚
â”‚  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚        â”‚
â”‚  â”‚   â€¢ Context valid.        â€¢ Vision analysis    â€¢ Text reason â”‚        â”‚
â”‚  â”‚   â€¢ Location filter       â€¢ Feature extract    â€¢ Description â”‚        â”‚
â”‚  â”‚   â€¢ Season reason.        â€¢ Multi-bird det.    â€¢ matching    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                               â”‚                                          â”‚
â”‚                               â–¼                                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                    â”‚   Deduplication &   â”‚                               â”‚
â”‚                    â”‚   Confidence Merge  â”‚                               â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                               â”‚                                          â”‚
â”‚                               â–¼                                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                    â”‚  STREAMING RESULTS  â”‚                               â”‚
â”‚                    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚                               â”‚
â”‚                    â”‚  â€¢ Real-time trail  â”‚                               â”‚
â”‚                    â”‚  â€¢ Unique species   â”‚                               â”‚
â”‚                    â”‚  â€¢ Wikipedia images â”‚                               â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Key Features

### 1. **Hybrid BirdNET + LLM Pipeline**
- BirdNET (Cornell Lab): Pattern-based spectrogram analysis for 6000+ species
- LLM Validation: Contextual reasoning using location, season, and behavior
- **Novel contribution**: Combines best of both approaches

### 2. **META SAM-Audio Processing**
- Inspired by Meta's Segment Anything Model
- Isolates bird calls from background noise
- Detects multiple birds in same recording
- Frequency band separation for multi-species detection

### 3. **Feature-Based Identification**
- Systematic feature analysis (beak, head, body patterns)
- No hardcoded species rules
- Flexible for any bird species

### 4. **Streaming Results**
- Real-time analysis trail shows progress
- Birds displayed as identified (not waiting for all)
- Deduplication ensures each species shown once

## ğŸš€ Quick Start

### Option 1: Cloud Hosting (FREE, Full BirdNET, Auto-Deploy)

Full Docker deployment with **BirdNET + TensorFlow** - same accuracy as local!

```bash
./deploy.sh cloud   # Shows step-by-step instructions
```

**Recommended: Google Cloud Run (FREE tier)**
- âœ… 2GB RAM (runs full BirdNET + TensorFlow)
- âœ… 2 million requests/month FREE
- âœ… Auto-deploy on git push

**Quick Setup:**
```bash
# 1. Install gcloud CLI, then:
gcloud auth login
gcloud run deploy birdsense --source=. --region=us-central1 --memory=2Gi --allow-unauthenticated

# 2. Get your URL: https://birdsense-xxx.run.app
```

### Option 2: Local (Best for Development)

```bash
./deploy.sh local   # Sets up Ollama + BirdNET + runs app
```

### Option 3: Docker

```bash
./deploy.sh docker  # Builds and runs full container locally
```

### Option 4: Manual Setup

```bash
# 1. Prerequisites
brew install python@3.12 ollama  # Mac
# Or: curl -fsSL https://ollama.ai/install.sh | sh  # Linux

# 2. Start Ollama and pull models
ollama serve &
ollama pull llava:7b
ollama pull phi4

# 3. Setup Python environment
cd birdsense
python3.12 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 4. Run
python app.py
# Open http://localhost:7860
```

### System Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| RAM | 8 GB | 16 GB |
| Storage | 15 GB | 25 GB |
| GPU | None (CPU works) | Apple M1+ or NVIDIA |
| Python | 3.12 | 3.12 |

## ğŸ“ Project Structure

```
birdsense/
â”œâ”€â”€ app.py              # Main app (auto-detects Ollama or Groq)
â”œâ”€â”€ prompts.py          # External LLM prompts
â”œâ”€â”€ confusion_rules.py  # Feature-based validation
â”œâ”€â”€ feedback.py         # Feedback & analytics collection
â”œâ”€â”€ export_data.py      # Export collected data
â”œâ”€â”€ deploy.sh           # One-command deployment
â”œâ”€â”€ Dockerfile          # Full Docker image (BirdNET + TensorFlow)
â”œâ”€â”€ docker-compose.yml  # Local multi-container setup
â”œâ”€â”€ cloudbuild.yaml     # Google Cloud Run auto-deploy
â”œâ”€â”€ fly.toml            # Fly.io deployment config
â”œâ”€â”€ requirements.txt    # All dependencies (BirdNET included)
â”œâ”€â”€ .github/workflows/  # CI/CD pipeline
â””â”€â”€ README.md           # This file
```

### Full Feature Parity: Local = Cloud

| Feature | Local | Cloud (Docker) |
|---------|-------|----------------|
| **BirdNET** | âœ… | âœ… |
| **TensorFlow** | âœ… | âœ… |
| **LLM Vision** | Ollama LLaVA | Groq Llama 3.2 |
| **LLM Text** | Ollama phi4 | Groq Llama 3.3 |
| **Accuracy** | Full | Full |

## ğŸ”§ Technology Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| Audio ID | BirdNET (Cornell) + TensorFlow | Spectrogram pattern matching |
| Image ID | LLaVA 7B | Vision-language analysis |
| Text ID | phi4 (14B) | Reasoning & validation |
| Audio Processing | META SAM-Audio | Noise filtering, call isolation |
| UI | Gradio | Web interface |
| Image Source | Wikipedia/iNaturalist | Reference photos |

## ğŸ§ª What Makes BirdSense Novel

1. **Hybrid Ensemble**: First to combine BirdNET + LLM for bird ID
2. **Contextual Validation**: LLM validates ML predictions using location/season
3. **Multi-Modal Fusion**: Audio + Image + Description analysis
4. **Streaming UX**: Real-time progress and results
5. **100% Local**: No cloud APIs required

## ğŸ“Š Comparison

| Feature | BirdNET Only | GPT-5 | BirdSense |
|---------|-------------|-------|-----------|
| Spectrogram Analysis | âœ… | âŒ | âœ… |
| Contextual Reasoning | âŒ | âœ… | âœ… |
| Location Awareness | Basic | âœ… | âœ… |
| Multi-modal | Audio only | Text/Image | **All 3** |
| Runs Locally | âœ… | âŒ | âœ… |
| Species Count | 6000+ | General | **6000+** |

## ğŸŒ Hosting for Testing

Share BirdSense with others for testing and feedback collection:

### Quick Share (Gradio Public URL)

```bash
# Creates a temporary public URL (valid for 72 hours)
python host.py

# Output: "Running on public URL: https://xxx.gradio.live"
```

This uses Gradio's built-in sharing feature - no extra setup required!

### Persistent Hosting Options

| Method | Cost | Setup Complexity | GPU |
|--------|------|------------------|-----|
| **Gradio Share** | Free | â­ (1 command) | Your local GPU |
| **ngrok** | Free tier | â­â­ | Your local GPU |
| **Railway.app** | ~$5/mo | â­â­â­ | CPU only (slow) |
| **VPS + Ollama** | ~$20/mo | â­â­â­â­ | Depends on VPS |

### Share Link Workflow

```bash
# 1. Start public hosting
python host.py

# 2. Share the gradio.live URL with testers
# 3. Testers use the Feedback tab to report results
# 4. Export feedback when done:
python export_data.py --export all
```

## ğŸ“Š Feedback & Sample Collection

BirdSense includes built-in audit and feedback collection:

### In-App Feedback
- **Feedback Tab**: Users can report if identification was correct/incorrect
- **Correct Species**: When wrong, users can provide the correct species
- **Notes**: Additional feedback for edge cases

### Data Export

```bash
# Show summary of collected data
python export_data.py

# Export feedback as JSON
python export_data.py --export feedback

# Export samples (audio/images with corrections)
python export_data.py --export samples

# Export everything
python export_data.py --export all
```

### Analytics Dashboard
Access the **ğŸ“Š Analytics** tab in the app to see:
- Total predictions
- Accuracy from user feedback
- Top identified species
- Breakdown by input type

## ğŸ“ Project Structure

```
birdsense/
â”œâ”€â”€ app.py              # Main application (Gradio UI + pipelines)
â”œâ”€â”€ prompts.py          # External LLM prompts (no hardcoding)
â”œâ”€â”€ confusion_rules.py  # Feature-based validation
â”œâ”€â”€ feedback.py         # Feedback & sample collection
â”œâ”€â”€ host.py             # Public hosting script
â”œâ”€â”€ export_data.py      # Data export utility
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md           # This file
```

## ğŸ”® Future Roadmap

- [ ] Geolocation auto-filtering (lat/lon based species filtering)
- [ ] Spectrogram visualization
- [ ] Custom model fine-tuning on regional data
- [ ] Mobile app (TensorFlow Lite)
- [ ] Offline mode with embedded models

---

**Developed by Soham** | BirdSense v1.0
