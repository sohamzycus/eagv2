# ğŸ¦ BirdSense - AI Bird Identification System

**Developed by Soham**

A novel hybrid AI system for intelligent bird identification using audio, images, and descriptions. BirdSense combines cutting-edge deep learning with traditional ornithological knowledge to deliver accurate species identification.

---

## ğŸŒŸ Key Features

| Feature | Description |
|---------|-------------|
| **ğŸµ Audio Identification** | META SAM-Audio + BirdNET hybrid with multi-bird detection |
| **ğŸ“· Image Identification** | Vision AI with feature-based analysis |
| **ğŸ“ Description Matching** | Natural language bird identification |
| **ğŸ‡®ğŸ‡³ India-Specific Info** | Local names, habitats, birding spots |
| **ğŸ”„ Multi-Backend Support** | Ollama (local) or Azure OpenAI (cloud) |
| **ğŸ“Š Streaming Results** | Real-time analysis trail with accordion view |

---

## ğŸ—ï¸ Novel Hybrid Architecture

BirdSense introduces a **novel multi-stage hybrid architecture** that combines specialized ML models with large language models for superior accuracy.

### Audio Identification Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BIRDSENSE AUDIO PIPELINE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  AUDIO INPUT                                                        â”‚
â”‚       â”‚                                                             â”‚
â”‚       â–¼                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚  STAGE 1: META SAM-Audio            â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Noise filtering                â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Bird call segmentation         â”‚                           â”‚
â”‚  â”‚  â””â”€â”€ Frequency band separation:     â”‚                           â”‚
â”‚  â”‚      â€¢ Very Low (100-500 Hz) - Owls â”‚                           â”‚
â”‚  â”‚      â€¢ Low (500-1500 Hz) - Crows    â”‚                           â”‚
â”‚  â”‚      â€¢ Medium (1500-3000 Hz) - Mynasâ”‚                           â”‚
â”‚  â”‚      â€¢ High (3000-6000 Hz) - Finchesâ”‚                           â”‚
â”‚  â”‚      â€¢ Very High (6000+ Hz)         â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚       â”‚                                                             â”‚
â”‚       â–¼                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚  STAGE 2: BirdNET (Cornell Lab)     â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Spectrogram analysis           â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ 6000+ species recognition      â”‚                           â”‚
â”‚  â”‚  â””â”€â”€ Multi-pass analysis:           â”‚                           â”‚
â”‚  â”‚      â€¢ Full audio analysis          â”‚                           â”‚
â”‚  â”‚      â€¢ Per-frequency-band analysis  â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚       â”‚                                                             â”‚
â”‚       â–¼                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚  STAGE 3: Feature Extraction        â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Frequency range analysis       â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Pattern detection              â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Syllable counting              â”‚                           â”‚
â”‚  â”‚  â””â”€â”€ Rhythm classification          â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚       â”‚                                                             â”‚
â”‚       â–¼                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚  STAGE 4: LLM Validation Layer      â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Contextual reasoning           â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Location/season validation     â”‚                           â”‚
â”‚  â”‚  â””â”€â”€ Confidence adjustment          â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚       â”‚                                                             â”‚
â”‚       â–¼                                                             â”‚
â”‚  IDENTIFIED BIRDS (with enriched info)                             â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Image Identification Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BIRDSENSE IMAGE PIPELINE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  IMAGE INPUT                                                        â”‚
â”‚       â”‚                                                             â”‚
â”‚       â–¼                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚  Vision Model (LLaVA/GPT-4o)        â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Systematic feature analysis:   â”‚                           â”‚
â”‚  â”‚  â”‚   â€¢ BEAK: Color, shape           â”‚                           â”‚
â”‚  â”‚  â”‚   â€¢ HEAD: Crown, eye pattern     â”‚                           â”‚
â”‚  â”‚  â”‚   â€¢ BODY: Plumage, breast        â”‚                           â”‚
â”‚  â”‚  â”‚   â€¢ SIZE: Relative sizing        â”‚                           â”‚
â”‚  â”‚  â””â”€â”€ Multi-bird detection           â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚       â”‚                                                             â”‚
â”‚       â–¼                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚  Enrichment Layer                   â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Wikipedia image fetch          â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Species information            â”‚                           â”‚
â”‚  â”‚  â”œâ”€â”€ Habitat & diet data            â”‚                           â”‚
â”‚  â”‚  â””â”€â”€ India-specific info            â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚       â”‚                                                             â”‚
â”‚       â–¼                                                             â”‚
â”‚  IDENTIFIED BIRDS (with images & facts)                            â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
birdsense/
â”œâ”€â”€ app.py              # Gradio UI (clean, minimal)
â”œâ”€â”€ providers.py        # LLM Provider Factory Pattern
â”œâ”€â”€ analysis.py         # Bird Identification Logic
â”œâ”€â”€ prompts.py          # Model-specific prompts
â”œâ”€â”€ confusion_rules.py  # Feature validation hints
â”œâ”€â”€ feedback.py         # User feedback collection
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ Dockerfile          # Cloud deployment
â”œâ”€â”€ .env               # Local configuration (gitignored)
â”‚
â”œâ”€â”€ api/               # REST API (FastAPI)
â”‚   â”œâ”€â”€ main.py        # API server entry point
â”‚   â”œâ”€â”€ routes/        # API endpoints
â”‚   â”‚   â”œâ”€â”€ auth_routes.py      # JWT authentication
â”‚   â”‚   â””â”€â”€ identify_routes.py  # Bird identification
â”‚   â”œâ”€â”€ auth/          # JWT handler
â”‚   â””â”€â”€ models/        # Pydantic schemas
â”‚
â””â”€â”€ mobile/            # React Native Expo App
    â”œâ”€â”€ app/           # Expo Router screens
    â”‚   â”œâ”€â”€ (tabs)/    # Tab navigation
    â”‚   â””â”€â”€ login.tsx  # Authentication
    â””â”€â”€ src/
        â”œâ”€â”€ services/  # API client
        â”œâ”€â”€ context/   # Auth context
        â””â”€â”€ components/# Reusable UI
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.12
- Ollama (for local models)
- Docker (for cloud deployment)

### Local Development

#### 1. Clone and Setup

```bash
cd birdsense

# Create virtual environment
python3.12 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

#### 2. Install Ollama Models (Local Backend)

```bash
# Install Ollama from https://ollama.ai
ollama pull llava:7b      # Vision model
ollama pull phi4:latest   # Text model
```

#### 3. Configure Environment

```bash
# Copy template
cp env-template.txt .env

# Edit .env with your settings:
# Option A: Use Ollama (local) - no API key needed
# Option B: Use Azure OpenAI - add your credentials
```

**Example `.env` for Azure OpenAI:**
```env
IS_AZURE=true
LITELLM_API_KEY=your-azure-api-key
LITELLM_API_BASE=https://your-resource.azure-api.net/your-endpoint
AZURE_DEPLOYMENT=your-deployment-name
AZURE_API_VERSION=2024-02-15-preview
LITELLM_VISION_MODEL=gpt-4o
LITELLM_TEXT_MODEL=gpt-4o
```

#### 4. Run Locally

```bash
python app.py
```

Open **http://localhost:7860** in your browser.

---

## ğŸ”Œ REST API

BirdSense includes a FastAPI-based REST API for programmatic access.

### Run API Server

```bash
cd birdsense
source venv/bin/activate
uvicorn api.main:app --reload --port 8000
```

**Swagger UI**: http://localhost:8000/docs  
**ReDoc**: http://localhost:8000/redoc

### API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/auth/login` | Get JWT token |
| `GET` | `/auth/me` | Get current user |
| `POST` | `/identify/audio` | Upload audio file |
| `POST` | `/identify/audio/base64` | Base64 audio |
| `POST` | `/identify/image` | Upload image file |
| `POST` | `/identify/image/base64` | Base64 image |
| `POST` | `/identify/description` | Text description |

### Authentication

Default users:

| Username | Password |
|----------|----------|
| `mazycus` | `ZycusMerlinAssist@2024` |
| `demo` | `demo123` |
| `soham` | `birdsense2024` |

### Postman Collection

Import `api/BirdSense_API.postman_collection.json` into Postman for ready-to-use requests.

---

## ğŸ“± Mobile App (React Native)

A cross-platform mobile app built with Expo.

### Run Mobile App

```bash
cd birdsense/mobile

# Install dependencies
npm install

# Start Expo
npm start

# Scan QR code with Expo Go app
```

### Features

- ğŸµ **Audio Recording** - Record and identify bird calls
- ğŸ“· **Camera/Gallery** - Take or select bird photos
- ğŸ“ **Description** - Text-based identification
- ğŸ” **Authentication** - JWT-based login

### Configure API URL

Edit `mobile/src/services/api.ts`:

```typescript
const API_CONFIG = {
  BASE_URL: 'https://your-deployed-api.run.app',
};
```

---

## â˜ï¸ Cloud Deployment

### Deploy to Google Cloud Run

#### 1. Build Docker Image

```bash
# Build for linux/amd64 (Cloud Run requirement)
docker buildx build --platform linux/amd64 -t your-dockerhub/birdsense:latest --push .
```

#### 2. Deploy to Cloud Run

```bash
gcloud run deploy birdsense \
  --image docker.io/your-dockerhub/birdsense:latest \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --memory 2Gi \
  --cpu 2 \
  --timeout 300 \
  --set-env-vars "IS_AZURE=true" \
  --set-env-vars "LITELLM_API_KEY=your-api-key" \
  --set-env-vars "LITELLM_API_BASE=https://your-endpoint" \
  --set-env-vars "AZURE_DEPLOYMENT=your-deployment" \
  --set-env-vars "AZURE_API_VERSION=2024-02-15-preview" \
  --set-env-vars "LITELLM_VISION_MODEL=gpt-4o" \
  --set-env-vars "LITELLM_TEXT_MODEL=gpt-4o" \
  --port 7860
```

#### 3. Verify Deployment

```bash
# Get service URL
gcloud run services describe birdsense --region us-central1 --format 'value(status.url)'

# Test
curl https://your-service-url.run.app
```

### Deploy with Docker Compose (Self-hosted)

```yaml
# docker-compose.yml
version: '3.8'
services:
  birdsense:
    image: your-dockerhub/birdsense:latest
    ports:
      - "7860:7860"
    environment:
      - IS_AZURE=true
      - LITELLM_API_KEY=${LITELLM_API_KEY}
      - LITELLM_API_BASE=${LITELLM_API_BASE}
      - AZURE_DEPLOYMENT=${AZURE_DEPLOYMENT}
    restart: unless-stopped
```

```bash
docker-compose up -d
```

---

## ğŸ”§ Backend Configuration

### Option 1: Ollama (Local - Free)

Best for development and privacy-conscious deployments.

| Model | Purpose | Size |
|-------|---------|------|
| LLaVA 7B | Vision | ~4GB |
| phi4 14B | Text/Reasoning | ~8GB |

**Quality**: â­â­â­â­ (Good)

### Option 2: Azure OpenAI (Enterprise)

Best for production with enterprise security.

| Model | Purpose |
|-------|---------|
| GPT-4o | Vision + Text |

**Quality**: â­â­â­â­â­ (Excellent)

### Option 3: OpenAI Public API

Best for quick cloud deployment.

```env
IS_AZURE=false
LITELLM_API_KEY=sk-your-openai-key
LITELLM_API_BASE=https://api.openai.com
LITELLM_VISION_MODEL=gpt-4o
LITELLM_TEXT_MODEL=gpt-4o
```

---

## ğŸ¯ API Endpoints

BirdSense uses Gradio's built-in API. Access programmatically:

```python
from gradio_client import Client

client = Client("https://your-birdsense-url")

# Image identification
result = client.predict(
    image="path/to/bird.jpg",
    location="Mumbai, India",
    api_name="/identify_image"
)

# Audio identification  
result = client.predict(
    audio="path/to/bird_call.wav",
    location="Kerala, India",
    month="March",
    api_name="/identify_audio"
)
```

---

## ğŸ“Š Technical Stack

| Component | Technology |
|-----------|------------|
| **Web UI** | Gradio 4.x |
| **REST API** | FastAPI + Uvicorn |
| **Mobile App** | React Native (Expo) |
| **Audio Analysis** | BirdNET (TensorFlow), scipy, librosa |
| **Vision Models** | LLaVA 7B, GPT-4o |
| **Text Models** | phi4 14B, GPT-4o |
| **Authentication** | JWT (python-jose, passlib) |
| **Image Sources** | Wikipedia, Wikimedia Commons, iNaturalist |
| **Containerization** | Docker |
| **Cloud Platform** | Google Cloud Run |

---

## ğŸ§ª Testing

### Test Audio Multi-Bird Detection

```python
# Verify SAM-Audio + BirdNET pipeline
from analysis import identify_audio_streaming
import numpy as np

# Generate test audio or load from file
# The pipeline will:
# 1. Separate frequency bands
# 2. Run BirdNET on each band
# 3. Deduplicate and merge results
```

### Test Image Identification

```python
from analysis import fetch_bird_image

# Verify image fetching uses scientific name
url = fetch_bird_image("Great Tit", "Parus major")
print(f"Image URL: {url}")  # Should return Wikipedia image
```

---

## ğŸ”„ Recent Updates

### v6.0 (Latest)
- âœ… **REST API** - FastAPI endpoints with Swagger docs
- âœ… **Mobile App** - React Native Expo app
- âœ… **JWT Authentication** - Secure API access
- âœ… **Postman Collection** - Ready-to-use API tests

### v5.0
- âœ… **Multi-bird audio detection** via SAM-Audio frequency separation
- âœ… **Fixed bird image fetching** using scientific names
- âœ… **India-specific information** always included
- âœ… **Accordion UI** for multiple results
- âœ… **Refactored architecture** with Factory Pattern
- âœ… **Azure OpenAI support** for enterprise deployment

### Architecture
- `providers.py` - Clean LLM backend abstraction
- `analysis.py` - Separated identification logic
- `prompts.py` - Externalized all LLM prompts
- `api/` - REST API with Factory Pattern
- `mobile/` - Cross-platform mobile app

---

## ğŸ™ Acknowledgments

- **Cornell Lab of Ornithology** - BirdNET model
- **Meta AI** - LLaVA vision-language model
- **OpenAI / Microsoft** - GPT-4o models
- **Ollama** - Local model serving
- **Wikipedia / iNaturalist** - Bird images and data

---

**ğŸ¦ BirdSense** - *Bringing AI to Bird Identification*

*Developed by Soham*
